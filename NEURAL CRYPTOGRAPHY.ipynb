{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Convolutional Neural Networks to Cryptography for Encryption/Decryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Ria Cheruvu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle the issue of secure communication, I employed Convolutional Neural Networks (CNNs) for the encryption/decryption (128-bit key) and signing/verification functions. \n",
    "\n",
    "The following ipynb contains the parameter initialization, variable declaration, weight definition, model definition, user input, training, testing, and performance benchmarking against Fernet for encryption/decryption functions. \n",
    "\n",
    "The code is self-explanatory. To run the code, please run the cells in the TensorFlow framework one at a time.\n",
    "\n",
    "Please Note: User input is mandatory to achieve results. \n",
    "\n",
    "I ran the following code through Docker on a Windows 10 Machine with 16 GB RAM and 8-core 3.1 GHz CPU with hyper-threading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import socket\n",
    "import sys\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "crypto_msg_len = N = 16\n",
    "crypto_key_len = 16\n",
    "batch_size = 512\n",
    "epochs = 50\n",
    "learning_rate = 0.0008 #Optimizer learning rate\n",
    "\n",
    "# Function to generate n random messages and keys\n",
    "def gen_data(n=batch_size, msg_len=crypto_msg_len, key_len=crypto_key_len):\n",
    "    #return (np.random.randint(0, 2, size=(n, msg_len))*2-1), (np.random.randint(0, 2, size=(n, key_len))*2-1)\n",
    "    return (np.random.randint(0, 2, size=(n, msg_len))), (np.random.randint(0, 2, size=(n, key_len)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def conv1d(input_, filter_shape, stride, name=\"conv1d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', shape=filter_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv = tf.nn.conv1d(input_, w, stride, padding='SAME')\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Cryptography Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of “secure communication” can be described as follows: Generation of the key, the encryption/decryption algorithm, sending the message (platform). An example scenario is as follows: The goal is for Alice to send a message to Bob, and Eve, a party trying to hack into Alice and Bob’s communication, to be unable to read the message. Alice takes a message (plain text) and uses the key she shares with Bob to encrypt plain text into cipher text. This cipher text is sent to Bob, who consumes the communication and key, and decrypts the cipher text into plain text. Eve intercepts the communication of the cipher text, and attempts to recover the plaintext with no knowledge of the keys and in some cases, the encryption algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the original algorithm, I modified adopted code from Liam Schoneveld and GitHub user ankeshanand  to include the convolutional layers and experimented with the parameters by changing the learning rate of the optimizer, the epochs for training and testing, the initial weights, etc. I used the TensorFlow framework and abandoned implementation with the Theano framework, due to lack of CPU optimization libraries on Windows 10; NCA has been implemented in Theano, TensorFlow, and regular python framework by different authors, however, the base algorithm remains the same. I ran the following code through Docker on a Windows 10 Machine with 16 GB RAM and 8-core 3.1 GHz CPU with hyper-threading.\n",
    "\n",
    "I experimented with the Adam optimizer, Adagrad optimizer, and Momentum optimizer, which use the loss functions for minimizing error. Next, I designed the UI accompanying the NCA algorithm. The user can enter input in ASCII, which is then converted to binary and structured appropriately in order to be accepted by np.array for both encryption/decryption and signing/verification functions.\n",
    "\n",
    "For socket communication, the user (Alice) types in a plaintext message, which is then encrypted (cipher text) and sent to Bob’s socket. Upon receiving the cipher text, Bob’s shared key is used to decrypt the message and Bob prints out the recovered message.\n",
    "\n",
    "### Adopted from <cite>\"Learning to Protect Communications with Adversarial Neural Cryptography\" by Abadi, M & Andersen, D.</cite><br/><cite>https://nlml.github.io/neural-networks/adversarial-neural-cryptography/</cite><br/><cite> https://github.com/ankeshanand/neural-cryptography-tensorflow</cite> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Placeholder variables for Message and Key\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m, crypto_msg_len])\n\u001b[0;32m      3\u001b[0m key \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mplaceholder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m, crypto_key_len])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Weights for fully connected layers\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Placeholder variables for Message and Key\n",
    "msg = tf.placeholder(\"float\", [None, crypto_msg_len])\n",
    "key = tf.placeholder(\"float\", [None, crypto_key_len])\n",
    "\n",
    "# Weights for fully connected layers\n",
    "w_alice = tf.get_variable(\"alice_w\", shape=[2 * N, 2 * N], initializer=tf.contrib.layers.xavier_initializer())\n",
    "w_bob = tf.get_variable(\"bob_w\", shape=[2 * N, 2 * N], initializer=tf.contrib.layers.xavier_initializer())\n",
    "w_eve1 = tf.get_variable(\"eve_w1\", shape=[N, 2 * N], initializer=tf.contrib.layers.xavier_initializer())\n",
    "w_eve2 = tf.get_variable(\"eve_w2\", shape=[2 * N, 2 * N], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "# Alice's Machine Network\n",
    "# FC layer -> Conv Layer (4 1-D convolutions)\n",
    "alice_input = tf.concat(concat_dim=1, values=[msg, key])\n",
    "alice_hidden = tf.nn.sigmoid(tf.matmul(alice_input, w_alice))\n",
    "alice_hidden = tf.expand_dims(alice_hidden, 2)\n",
    "\n",
    "h0 = tf.nn.relu(conv1d(alice_hidden, [4,1,2], stride=1, name=\"alice\"+'_h0_conv'))\n",
    "h1 = tf.nn.relu(conv1d(h0, [2,2,4], stride=2, name=\"alice\"+'_h1_conv'))\n",
    "h2 = tf.nn.relu(conv1d(h1, [1,4,4], stride=1, name=\"alice\"+'_h2_conv'))\n",
    "h3 = tf.nn.tanh(conv1d(h2, [1,4,1], stride=1, name=\"alice\"+'_h3_conv'))\n",
    "alice_output = tf.squeeze(h3) # eliminate dimensions of size 1 from the shape of a tensor\n",
    "\n",
    "\n",
    "(conv1d(h0, [2,2,4], stride=2, name=\"bob\"+'_h1_conv'))\n",
    "h2 = tf.nn.relu(conv1d(h1, [1,4,4], stride=1, name=\"bob\"+'_h2_conv'))\n",
    "h3 = tf.nn.tanh(conv1d(h2, [1,4,1], stride=1, name=\"bob\"+'_h3_conv'))\n",
    "bob_output = tf.squeeze(h3) # eliminate dimensions of size 1 from the shape of a tensor\n",
    "\n",
    "# Eve's Machine Network\n",
    "# FC layer -> FC layer -> Conv Layer (4 1-D convolutions)\n",
    "eve_input = alice_output\n",
    "eve_hidden1 = tf.nn.sigmoid(tf.matmul(eve_input, w_eve1))\n",
    "eve_hidden2 = tf.nn.sigmoid(tf.matmul(eve_hidden1, w_eve2))\n",
    "eve_hidden2 = tf.expand_dims(eve_hidden2, 2)\n",
    "\n",
    "h0 = tf.nn.relu(conv1d(eve_hidden2, [4,1,2], stride=1, name=\"eve\"+'_h0_conv'))\n",
    "h1 = tf.nn.relu(conv1d(h0, [2,2,4], stride=2, name=\"eve\"+'_h1_conv'))\n",
    "h2 = tf.nn.relu(conv1d(h1, [1,4,4], stride=1, name=\"eve\"+'_h2_conv'))\n",
    "h3 = tf.nn.tanh(conv1d(h2, [1,4,1], stride=1, name=\"eve\"+'_h3_conv'))\n",
    "eve_output = tf.squeeze(h3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Cryptography Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eve_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m alice_errors, bob_errors, eve_errors \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loss Functions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m decrypt_err_eve \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mabs(msg \u001b[38;5;241m-\u001b[39m \u001b[43meve_output\u001b[49m))\n\u001b[0;32m      5\u001b[0m decrypt_err_alice \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mabs(msg \u001b[38;5;241m-\u001b[39m alice_output))\n\u001b[0;32m      6\u001b[0m loss_alice \u001b[38;5;241m=\u001b[39m decrypt_err_alice \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m decrypt_err_eve) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eve_output' is not defined"
     ]
    }
   ],
   "source": [
    "alice_errors, bob_errors, eve_errors = [], [], []\n",
    "\n",
    "# Loss Functions\n",
    "decrypt_err_eve = tf.reduce_mean(tf.abs(msg - eve_output))\n",
    "decrypt_err_alice = tf.reduce_mean(tf.abs(msg - alice_output))\n",
    "loss_alice = decrypt_err_alice + (1. - decrypt_err_eve) ** 2.\n",
    "decrypt_err_bob = tf.reduce_mean(tf.abs(msg - bob_output))\n",
    "loss_bob = decrypt_err_bob + (1. - decrypt_err_eve) ** 2.\n",
    "\n",
    "# Get training variables corresponding to each network\n",
    "t_vars = tf.trainable_variables()\n",
    "alice_vars = [var for var in t_vars if 'alice_' in var.name]\n",
    "bob_vars =   [var for var in t_vars if 'bob_' in var.name]\n",
    "eve_vars =   [var for var in t_vars if 'eve_' in var.name]\n",
    "\n",
    "# Build the optimizers, can play with different optimizers\n",
    "\n",
    "'''\n",
    "alice_optimizer = tf.train.AdagradOptimizer(learning_rate, initial_accumulator_value=0.1, \n",
    "                       use_locking=False, name='Adagrad').minimize(loss_alice, var_list=alice_vars)\n",
    "bob_optimizer = tf.train.AdagradOptimizer(learning_rate, initial_accumulator_value=0.1, \n",
    "                        use_locking=False, name='Adagrad').minimize(loss_bob, var_list=bob_vars)\n",
    "eve_optimizer = tf.train.AdagradOptimizer(learning_rate, initial_accumulator_value=0.1, \n",
    "                        use_locking=False, name='Adagrad').minimize(decrypt_err_eve, var_list=eve_vars)\n",
    "\n",
    "alice_optimizer = tf.train.MomentumOptimizer(0.01, 0.9).minimize(loss_alice, var_list=alice_vars)   \n",
    "bob_optimizer = tf.train.MomentumOptimizer(0.01, 0.9).minimize(loss_bob, var_list=bob_vars)\n",
    "eve_optimizer = tf.train.MomentumOptimizer(0.01, 0.9).minimize(decrypt_err_eve, var_list=eve_vars)\n",
    "\n",
    "'''\n",
    "alice_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_alice, var_list=alice_vars)   \n",
    "bob_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_bob, var_list=bob_vars)\n",
    "eve_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(decrypt_err_eve, var_list=eve_vars)\n",
    "\n",
    "def train(sess):\n",
    "    # Begin Training\n",
    "    tf.initialize_all_variables().run(session=sess)\n",
    "    for i in range(epochs):\n",
    "        iterations = 2000\n",
    "\n",
    "        alice_loss, _, _ = _train('alice', iterations, sess)\n",
    "        alice_errors.append(alice_loss)\n",
    "        print( 'Training Alice, Epoch:', i + 1, ' error: ', alice_loss)\n",
    "\n",
    "        _, bob_loss, _ = _train('bob', iterations, sess)\n",
    "        bob_errors.append(bob_loss)\n",
    "        print( 'Training Bob, Epoch:', i + 1, ' error: ', bob_loss)\n",
    "\n",
    "        _, _, eve_loss = _train('eve', iterations, sess)\n",
    "        eve_errors.append(eve_loss)   \n",
    "        print( 'Training Eve, Epoch:', i + 1, ' error: ', eve_loss)\n",
    "\n",
    "\n",
    "def _train(network, iterations, sess):\n",
    "    alice_decrypt_error, bob_decrypt_error, eve_decrypt_error = 1., 1., 1.\n",
    "\n",
    "    bs = batch_size\n",
    "    # Train Eve for two minibatches to give it a slight computational edge\n",
    "    if network == 'eve':\n",
    "        bs *= 2\n",
    "\n",
    "    for i in range(iterations):\n",
    "        msg_in_val, key_val = gen_data(n=bs, msg_len=crypto_msg_len, key_len=crypto_key_len)\n",
    "        feed_dict={msg: msg_in_val, key: key_val}\n",
    "        if network == 'alice':\n",
    "            _, decrypt_err = sess.run([alice_optimizer, decrypt_err_alice], feed_dict = feed_dict)\n",
    "            alice_decrypt_error = min(alice_decrypt_error, decrypt_err)\n",
    "        elif network == 'bob':\n",
    "            _, decrypt_err = sess.run([bob_optimizer, decrypt_err_bob], feed_dict = feed_dict)\n",
    "            bob_decrypt_error = min(bob_decrypt_error, decrypt_err)\n",
    "        elif network == 'eve':\n",
    "            _, decrypt_err = sess.run([eve_optimizer, decrypt_err_eve], feed_dict = feed_dict)\n",
    "            eve_decrypt_error = min(eve_decrypt_error, decrypt_err)\n",
    "\n",
    "    return alice_decrypt_error, bob_decrypt_error, eve_decrypt_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Cryptography Testing Helper Functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This section of the code takes input and prepares it for the socket communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter some text:  we are humans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01110111 01100101 00100000 01100001 01110010 01100101 00100000 01101000 01110101 01101101 01100001 01101110 01110011\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#b1 = b1.zfill(48)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(b1)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m16\u001b[39m\n\u001b[1;32m----> 8\u001b[0m v1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(b1)):\n\u001b[0;32m     10\u001b[0m     v1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(v1, \u001b[38;5;28mint\u001b[39m(b1[i]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "text = input('Enter some text: ')\n",
    "bintext = ' '.join('{0:08b}'.format(ord(x), 'b') for x in text)\n",
    "print (bintext)\n",
    "b1  = bintext.replace(\" \", \"\")\n",
    "#b1 = b1.zfill(48)\n",
    "pad = len(b1)%16\n",
    "\n",
    "v1 = np.array([])\n",
    "for i in range(0, len(b1)):\n",
    "    v1 = np.append(v1, int(b1[i]))\n",
    "\n",
    "#apply the padding\n",
    "for i in range(0, pad):\n",
    "    v1 = np.append(v1, int(0))\n",
    "total_len = len(b1) + pad\n",
    "\n",
    "plaintext_to_Alice = v1.reshape(int(total_len/16), 16)\n",
    "print('plaintext_to_Alice = ', plaintext_to_Alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user (Alice) inputs a message to send to Bob's socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sock_send(message):\n",
    "    # Create a TCP/IP socket\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_address = ('localhost', 10000)\n",
    "    sock.connect(server_address)\n",
    "    #To send data over network, you need to serialize it into an array of bytes,\n",
    "    #then deserialize it back. In Python, serialization of most objects can be done via pickle module:\n",
    "    print('message = ', message)\n",
    "    msg2 = pickle.dumps(message)\n",
    "    #print('msg2 = ', msg2)\n",
    "    sock.send(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting up on localhost port 10000\n"
     ]
    }
   ],
   "source": [
    "def sock_recv_init():\n",
    "    # Create a TCP/IP socket\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    # Bind the socket to the port\n",
    "    address = ('localhost', 10000)\n",
    "    print('starting up on %s port %s' % address)\n",
    "    sock.bind(address)\n",
    "    # Listen for incoming connections\n",
    "    sock.listen(1)\n",
    "    return sock\n",
    "\n",
    "def sock_recv(sock):\n",
    "    # Wait for a connection\n",
    "    print( 'waiting for a connection')\n",
    "    connection, client_address = sock.accept()\n",
    "    print('connection from', client_address)\n",
    "    # Receive the data (max 48 bytes)\n",
    "    data = connection.recv(1024*10)\n",
    "    #print('received \"%s\"' % data)\n",
    "    data1 = pickle.loads(data)\n",
    "    print('received ', data1)\n",
    "    return data1\n",
    "\n",
    "sock = sock_recv_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_file_msg = \"testmsg.txt\"\n",
    "test_file_keys = \"testkey.txt\"\n",
    "\n",
    "def test(network, sess):\n",
    "        alice_decrypt_error, bob_decrypt_error, eve_decrypt_error = 1., 1., 1.\n",
    "        alice_encrypt_time = 0\n",
    "        bob_decrypt_time = 0\n",
    "        bob_output_1 = 0\n",
    "        \n",
    "        #bs = 3 #batch_size\n",
    "        bs = int(total_len/16) #batch_size\n",
    "        messages, keys = gen_data(n=bs, msg_len=crypto_msg_len, key_len=crypto_key_len)\n",
    "        #test message to get the code complete\n",
    "        messages = np.array([\n",
    "                    [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1], \n",
    "                    [0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
    "                    [1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
    "                   ])\n",
    "\n",
    "\n",
    "        #feed_dict={msg: messages, key: keys}\n",
    "        feed_dict={msg: plaintext_to_Alice, key: keys}\n",
    "\n",
    "        print( 'messages = \\n', plaintext_to_Alice)\n",
    "        print( 'keys = \\n', keys)\n",
    "\n",
    "        if network == 'alice':\n",
    "            print('plaintext_to_Alice = ', plaintext_to_Alice)\n",
    "            start_time = time.time()\n",
    "            _, decrypt_err, alice_output_1  = sess.run([alice_optimizer, decrypt_err_alice, alice_output], feed_dict = feed_dict)\n",
    "            end_time = time.time()\n",
    "            alice_encrypt_time = end_time-start_time\n",
    "            print('test alice_output (***Cipher Text***) = \\n', alice_output_1)       \n",
    "            alice_decrypt_error = min(alice_decrypt_error, decrypt_err)\n",
    "            print('SOCK_SEND')\n",
    "            sock_send(alice_output_1)\n",
    "        elif network == 'bob':\n",
    "            print('SOCKET_RECV ==== \\n')\n",
    "            messages_sock = sock_recv(sock)\n",
    "            print(messages_sock)\n",
    "            feed_dict1 = {msg: messages_sock, key: keys}\n",
    "            start_time = time.time()\n",
    "            _, decrypt_err, bob_input_1, bob_output_1 = sess.run([bob_optimizer, decrypt_err_bob, bob_input, bob_output], feed_dict = feed_dict1)\n",
    "            end_time = time.time()\n",
    "            bob_decrypt_time = end_time-start_time\n",
    "            bob_input_1 = np.round(bob_input_1, 2)\n",
    "            bob_ouput_1 = np.round(bob_output_1, 2)\n",
    "            \n",
    "            print('test bob_input (***Cipher Text***) = \\n', bob_input_1, 2)       \n",
    "            print('test bob_output (***Plain Text***)= \\n',  bob_output_1, 2)       \n",
    "            bob_decrypt_error = min(bob_decrypt_error, decrypt_err)\n",
    "        elif network == 'eve':\n",
    "            _, decrypt_err = sess.run([eve_optimizer, decrypt_err_eve], feed_dict = feed_dict)\n",
    "            eve_decrypt_error = min(eve_decrypt_error, decrypt_err)\n",
    "\n",
    "        return alice_decrypt_error, alice_encrypt_time, bob_decrypt_error, bob_decrypt_time, bob_output_1, eve_decrypt_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the plot helper function. The plots demonstrate the decryption errors of the three parties per epoch when training the CNN and illustrate whether Eve was able to converge with Alice and Bob.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_results():\n",
    "    \"\"\"\n",
    "    Plot Lowest Decryption Errors achieved by Alice, Bob, and Eve per epoch\n",
    "    \"\"\"\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    plt.plot(alice_errors)\n",
    "    plt.plot(bob_errors)\n",
    "    plt.plot(eve_errors)\n",
    "    plt.legend(['alice', 'bob', 'eve'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Lowest Decryption error achieved')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TensorFlow Session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#sess = tf.InteractiveSession()\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sess \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#with tf.Session() as sess:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting Training Process... \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 100\n",
    "#sess = tf.InteractiveSession()\n",
    "sess = tf.Session()\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "print('Starting Training Process... ')\n",
    "start_time = time.time()\n",
    "train(sess)\n",
    "end_time = time.time()\n",
    "print('Time taken for Training (seconds): ', end_time-start_time)\n",
    "plot_results()\n",
    "\n",
    "print('alice_errors_train = ', alice_errors)\n",
    "print('bob_errors_train = ', bob_errors)\n",
    "print('eve_errors_train = ', eve_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above section of the code for training the CNN does not have to be rerun if the user decides to input another message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Alice\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Alice\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m----> 6\u001b[0m alice_loss_test, alice_encrypt_time, _, _, _,_ \u001b[38;5;241m=\u001b[39m test(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43msess\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malice_errors_test = \u001b[39m\u001b[38;5;124m'\u001b[39m, alice_loss_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Bob\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "\n",
    "#Test the Neural Crypto model\n",
    "start_time = time.time()\n",
    "print( 'Testing Alice' )\n",
    "alice_loss_test, alice_encrypt_time, _, _, _,_ = test('alice', sess)\n",
    "print('alice_errors_test = ', alice_loss_test)\n",
    "print( 'Testing Bob' )\n",
    "_,_, bob_loss_test, bob_decrypt_time, bob_output_1,_ = test('bob', sess)\n",
    "print('bob_errors_test = ', bob_loss_test)    \n",
    "print( 'Testing Eve' )\n",
    "_, _,_,_,_,eve_loss_test = test('eve', sess)\n",
    "print('eve_errors_test = ', eve_loss_test)\n",
    "end_time = time.time()\n",
    "print('Time taken for Testing (seconds): ', end_time-start_time)\n",
    "#convert to ASCII\n",
    "b1 = np.round(bob_output_1, 1)\n",
    "b1 = b1.ravel();\n",
    "b1 = np.abs(b1)\n",
    "print('bob_ouput_1 == ', b1)\n",
    "print('\\n')\n",
    "b2  = np.array2string(b1)\n",
    "b2 = b2.strip('[')\n",
    "b2 = b2.strip(']')\n",
    "b2 = b2.replace(\" \", \"\")\n",
    "b2 = b2.replace(\".\", \"\")\n",
    "b2 = b2.replace(\"\\n\", \"\")\n",
    "\n",
    "b2 = '0b'+b2\n",
    "print('b2 = ', b2)\n",
    "n = int(b2,2)\n",
    "str2 = n.to_bytes((n.bit_length() + 7) // 8, 'big').decode(errors='ignore')\n",
    "print(str2)\n",
    "\n",
    "print('Bob recovered Plain Text = ', str2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Performance Benchmarking with cryptography.fernet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fernet is an implementation of symmetric encryption. It uses AES for encryption and SHA256 for authentication, with initialization vectors generated using os.urandom(). The following code compares AES to NCA in terms of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2773730598.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install cryptography\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Install the Cryptography module\n",
    "pip install cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cryptography'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcryptography\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfernet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fernet\n\u001b[0;32m      2\u001b[0m key \u001b[38;5;241m=\u001b[39m Fernet\u001b[38;5;241m.\u001b[39mgenerate_key()\n\u001b[0;32m      3\u001b[0m cipher_suite \u001b[38;5;241m=\u001b[39m Fernet(key)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cryptography'"
     ]
    }
   ],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "#Preprocess the array from input block above\n",
    "v2 = []\n",
    "for i in range(0, len(b1)):\n",
    "    v2.append(int(b1[i]))\n",
    "    \n",
    "print('Cryptography.fernet AES Encrypt/Decrypt sessions')\n",
    "print('------------------------------------------------')\n",
    "\n",
    "start_time = time.time()\n",
    "cipher_text = cipher_suite.encrypt(bytes(v2))\n",
    "end_time = time.time()\n",
    "fernet_encrypt_time = end_time - start_time\n",
    "print('cipher text = ', cipher_text)\n",
    "\n",
    "start_time = time.time()\n",
    "plain_text = cipher_suite.decrypt(cipher_text)\n",
    "end_time = time.time()\n",
    "fernet_decrypt_time = end_time - start_time\n",
    "print('plain_text =  ', plain_text)\n",
    "\n",
    "print('*********Performance of NCA versus Cryptography.Fernet********************')\n",
    "print('Time taken for Alice to Encrypt the Plain Text (seconds): ', alice_encrypt_time)\n",
    "print('Time taken for Bob to Decrypt the Cipher Text (seconds): ', bob_decrypt_time)\n",
    "\n",
    "print('Time taken for Fernet to Encrypt the Plain Text (seconds): ', fernet_encrypt_time)\n",
    "print('Time taken for Fernet to Decrypt the Cipher Text (seconds): ', fernet_decrypt_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "I have demonstrated that it is possible to achieve low error rates multiple times with neural networks, despite the fact that CNNs are not consistent. The communication between Alice and Bob was simulated through sockets to demonstrate a real-life application of the CNNs on a TCP/IP network. There are numerous opportunities for NCA, including the possibility of using NCA for secure communication between autonomous IoT devices. Another opportunity for NCA would be for Artificial Intelligence due to its dynamically self-configurable nature and because it can function efficiently in massively parallel processing environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Work: The foremost concern is to try and improve the consistency of NCA through further hyperparameter tuning. Future work also includes implementing the sockets over Internet Protocol, instead of localhost. In addition, other goals include implementing Eve and her socket as part of the crypto-pipeline. Tests, such as performance benchmarking, can be performed against AES, SHA-256, and other encryption techniques to assess the strengths and weaknesses of the NCA algorithm for further improvement. \n",
    "\n",
    "Another important field that I would like to explore is the combination of quantum and neural cryptography. Quantum cryptography involves altering the contents of a message in transit as soon as the attacker (Eve) sees it; this guarantees the integrity of the message. For example, quantum cryptography could be used as a potential channel for transmission of messages encrypted through NCA.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
